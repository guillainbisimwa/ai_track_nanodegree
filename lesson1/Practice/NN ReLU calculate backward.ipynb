{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "#Download the training data and load it\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
    "        reconstruction also a PyTorch Tensor\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "#define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "optimization = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training losss 1.9821439159196068\n",
      "training losss 0.919256959039011\n",
      "training losss 0.5392602443186714\n",
      "training losss 0.43351896699748316\n",
      "training losss 0.3871707808552012\n"
     ]
    }
   ],
   "source": [
    "epoches = 5\n",
    "\n",
    "for e in range(epoches):\n",
    "    runing_loss = 0\n",
    "    i = 0\n",
    "    for images, labels in trainloader:\n",
    "        #print(images.shape)\n",
    "        #flatten images\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Todo training pass\n",
    "        optimization.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimization.step()\n",
    "        \n",
    "        runing_loss += loss.item()\n",
    "        i += 1\n",
    "    else:\n",
    "        print(\"training losss\",runing_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "\n",
    "#flatten images 1 , 784\n",
    "img = images.view(images.shape[0], -1)\n",
    "print(img.shape)\n",
    "\n",
    "image = images[0].view(1, 784)\n",
    "print(image.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(image)\n",
    "ps = F.softmax(logits, dim=1)\n",
    "view_classify(image.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
